{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eef4ffd",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534d9b2",
   "metadata": {},
   "source": [
    "## Data and device loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2edbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats= ((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)) #mean and std\n",
    "train_tfm= tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), # transormation of data together\n",
    "                       tt.RandomHorizontalFlip(),\n",
    "                       tt.ToTensor()])\n",
    "valid_tfm = tt.Compose([tt.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed22856",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tfm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=valid_tfm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab548f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = test_data\n",
    "train_ds = training_data\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a97fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_res9=400\n",
    "batch_size_res20=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader to load data in batches(mini batch)\n",
    "train_dl_res9= DataLoader(train_ds,batch_size_res9,shuffle=True, num_workers=3, pin_memory=True) \n",
    "valid_dl_res9= DataLoader(valid_ds, batch_size_res9, num_workers=3,pin_memory=True) \n",
    "\n",
    "train_dl_res20= DataLoader(train_ds,batch_size_res20,shuffle=True, num_workers=3, pin_memory=True) \n",
    "valid_dl_res20= DataLoader(valid_ds, batch_size_res20, num_workers=3,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb42434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_res9= DeviceDataLoader(train_dl_res9, device)\n",
    "valid_dl_res9 = DeviceDataLoader(valid_dl_res9, device)\n",
    "\n",
    "train_dl_res20= DeviceDataLoader(train_dl_res20, device)\n",
    "valid_dl_res20 = DeviceDataLoader(valid_dl_res20, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05bd09",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb0832",
   "metadata": {},
   "source": [
    "## Resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56527407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_res9(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block_res9(in_channels, 64)\n",
    "        self.conv2 = conv_block_res9(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block_res9(128, 128), conv_block_res9(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block_res9(128, 256, pool=True)\n",
    "        self.conv4 = conv_block_res9(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block_res9(512, 512), conv_block_res9(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_res20(in_channels, out_channels, stride=1):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def shortcut(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "class ResNet20(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, n):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        \n",
    "        # 32x32 map\n",
    "        self.conv1 = conv_block_res20(in_channels, 16)\n",
    "        self.reg32 = nn.Sequential(conv_block_res20(16,16), conv_block_res20(16,16))\n",
    "        \n",
    "        # 16x16 map\n",
    "        self.entry16 = nn.Sequential(conv_block_res20(16, 32, stride=2), conv_block_res20(32, 32))\n",
    "        self.short16 = shortcut(16, 32)\n",
    "        self.reg16 = nn.Sequential(conv_block_res20(32, 32), conv_block_res20(32, 32))\n",
    "        \n",
    "        # 8x8 map\n",
    "        self.entry8 = nn.Sequential(conv_block_res20(32, 64, stride=2), conv_block_res20(64, 64))\n",
    "        self.short8 = shortcut(32, 64)\n",
    "        self.reg8 = nn.Sequential(conv_block_res20(64, 64), conv_block_res20(64, 64))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.AvgPool2d(kernel_size=8, stride=None, padding=0), \n",
    "                                        nn.Linear(64, num_classes),\n",
    "                                       nn.Softmax())\n",
    "        # FOR DEBUGGING\n",
    "        self.avg = nn.AvgPool2d(kernel_size=8, stride=None, padding=0)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fcl = nn.Linear(64, num_classes)\n",
    "        self.sm = nn.Softmax()\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            out = self.reg32(out) + out\n",
    "            \n",
    "        out = self.entry16(out) + self.short16(out)\n",
    "        for i in range(self.n - 1):\n",
    "            out = self.reg16(out) + out\n",
    "            \n",
    "        out = self.entry8(out) + self.short8(out)\n",
    "        for i in range(self.n - 1):\n",
    "            out = self.reg8(out) + out\n",
    "\n",
    "        #out = self.classifier(out)\n",
    "        out = self.avg(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fcl(out)\n",
    "        out = self.sm(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d26cd8",
   "metadata": {},
   "source": [
    "## Transfer to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res9 = to_device(ResNet9(3,10), device)\n",
    "model_res20 = to_device(ResNet20(3,10,3), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2665f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()  # Realsing cuda memory otherwise might get cuda out of memory error\n",
    "    history = []\n",
    "    \n",
    "    #custom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train() #Setting training mode\n",
    "        train_losses = []\n",
    "        lrs = [] \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader) \n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ddd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test: if something's wrong with how we set up our model, we'll see it now\n",
    "history_res9 = [evaluate(model_res9, valid_dl_res9)]\n",
    "history_res20 = [evaluate(model_res20, valid_dl_res20)]\n",
    "\n",
    "print(history_res9)\n",
    "print(history_res20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9d283",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_res9 = 2\n",
    "epochs_res20 = 2\n",
    "\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_res9 += fit_one_cycle(epochs_res9, max_lr, model_res9, train_dl_res9, valid_dl_res9, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)\n",
    "print(\"ResNet9 Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_res20 += fit_one_cycle(epochs_res20, max_lr, model_res20, train_dl_res20, valid_dl_res20, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)\n",
    "print(\"ResNet20 Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf811b",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f761ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "    \n",
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history_res20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ffe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history_res20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36864672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lrs(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e16efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lrs(history_res20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
