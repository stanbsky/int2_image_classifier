{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intense-peeing",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-farming",
   "metadata": {},
   "source": [
    "## Data and device loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats= ((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)) #mean and std\n",
    "train_tfm= tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), # transormation of data together\n",
    "                       tt.RandomHorizontalFlip(),\n",
    "                       tt.ToTensor()])\n",
    "valid_tfm = tt.Compose([tt.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tfm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=valid_tfm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = test_data\n",
    "train_ds = training_data\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_res9=400\n",
    "batch_size_res20=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader to load data in batches(mini batch)\n",
    "train_dl_res9= DataLoader(train_ds,batch_size_res9,shuffle=True, num_workers=3, pin_memory=True) # WHY do we use num_workers=3? To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument num_workers to a positive integer.\n",
    "valid_dl_res9= DataLoader(valid_ds, batch_size_res9, num_workers=3,pin_memory=True) # WHAT is pin_memory=true ? If you load your samples in the Dataset on CPU and would like to push it during training to the GPU, you can speed up the host to device transfer by enabling pin_memory. This lets your DataLoader allocate the samples in page-locked memory, which speeds-up the transfer.\n",
    "\n",
    "train_dl_res20= DataLoader(train_ds,batch_size_res20,shuffle=True, num_workers=3, pin_memory=True) # WHY do we use num_workers=3? To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument num_workers to a positive integer.\n",
    "valid_dl_res20= DataLoader(valid_ds, batch_size_res20, num_workers=3,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_res9= DeviceDataLoader(train_dl_res9, device)\n",
    "valid_dl_res9 = DeviceDataLoader(valid_dl_res9, device)\n",
    "\n",
    "train_dl_res20= DeviceDataLoader(train_dl_res20, device)\n",
    "valid_dl_res20 = DeviceDataLoader(valid_dl_res20, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-fiction",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-nurse",
   "metadata": {},
   "source": [
    "## Resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_res9(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block_res9(in_channels, 64)\n",
    "        self.conv2 = conv_block_res9(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block_res9(128, 128), conv_block_res9(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block_res9(128, 256, pool=True)\n",
    "        self.conv4 = conv_block_res9(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block_res9(512, 512), conv_block_res9(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_res20(in_channels, out_channels, stride=1):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def shortcut(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "class ResNet20(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, n):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        \n",
    "        # 32x32 map\n",
    "        self.conv1 = conv_block_res20(in_channels, 16)\n",
    "        self.reg32 = nn.Sequential(conv_block_res20(16,16), conv_block_res20(16,16))\n",
    "        \n",
    "        # 16x16 map\n",
    "        self.entry16 = nn.Sequential(conv_block_res20(16, 32, stride=2), conv_block_res20(32, 32))\n",
    "        self.short16 = shortcut(16, 32)\n",
    "        self.reg16 = nn.Sequential(conv_block_res20(32, 32), conv_block_res20(32, 32))\n",
    "        \n",
    "        # 8x8 map\n",
    "        self.entry8 = nn.Sequential(conv_block_res20(32, 64, stride=2), conv_block_res20(64, 64))\n",
    "        self.short8 = shortcut(32, 64)\n",
    "        self.reg8 = nn.Sequential(conv_block_res20(64, 64), conv_block_res20(64, 64))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.AvgPool2d(kernel_size=8, stride=None, padding=0), \n",
    "                                        nn.Linear(64, num_classes),\n",
    "                                       nn.Softmax())\n",
    "        # FOR DEBUGGING\n",
    "        self.avg = nn.AvgPool2d(kernel_size=8, stride=None, padding=0)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fcl = nn.Linear(64, num_classes)\n",
    "        self.sm = nn.Softmax()\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            out = self.reg32(out) + out\n",
    "            \n",
    "        out = self.entry16(out) + self.short16(out)\n",
    "        for i in range(self.n - 1):\n",
    "            out = self.reg16(out) + out\n",
    "            \n",
    "        out = self.entry8(out) + self.short8(out)\n",
    "        for i in range(self.n - 1):\n",
    "            out = self.reg8(out) + out\n",
    "\n",
    "        #out = self.classifier(out)\n",
    "        out = self.avg(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fcl(out)\n",
    "        out = self.sm(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-panic",
   "metadata": {},
   "source": [
    "## Transfer to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res9 = to_device(ResNet9(3,10), device)\n",
    "model_res20 = to_device(ResNet20(3,10,3), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()  # Realsing cuda memory otherwise might get cuda out of memory error\n",
    "    history = []\n",
    "    \n",
    "    #custom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train() #Setting training mode\n",
    "        train_losses = []\n",
    "        lrs = [] # WHAT? - Learning Rate Schedules (seeks to adjust the learning rate during training by reducing the learning rate according to a pre-defined schedule.)\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            # WHY? - Sets the gradients of all optimized torch.Tensors to zero. This will in general have lower memory footprint, and can modestly improve performance. \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader) # WHAT does this return exactly out of what's printed? {'val_loss': 0.9773819446563721, 'val_acc': 0.6523000597953796}\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test: if something's wrong with how we set up our model, we'll see it now\n",
    "history_res9 = [evaluate(model_res9, valid_dl_res9)]\n",
    "history_res20 = [evaluate(model_res20, valid_dl_res20)]\n",
    "\n",
    "print(history_res9)\n",
    "print(history_res20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-princeton",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_res9 = 70\n",
    "epochs_res20 = 400\n",
    "\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_res9 += fit_one_cycle(epochs_res9, max_lr, model_res9, train_dl_res9, valid_dl_res9, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)\n",
    "print(\"ResNet9 Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_res20 += fit_one_cycle(epochs_res20, max_lr, model_res20, train_dl_res20, valid_dl_res20, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)\n",
    "print(\"ResNet20 Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-salem",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "    \n",
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history_res20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history_res20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lrs(history_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lrs(history_res20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
